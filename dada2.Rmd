---
title: "DADA2"
author: "Joshua Geiger"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#https://benjjneb.github.io/dada2/tutorial_1_8.html
#https://bioconductor.org/packages/release/bioc/vignettes/dada2/inst/doc/dada2-intro.html

library(dada2)
library(ShortRead)
library(Biostrings)
library(ggplot2)
require(ggseqlogo)

fnF1 <- system.file("extdata", "sam1F.fastq.gz", package="dada2")
fnR1 <- system.file("extdata", "sam1R.fastq.gz", package="dada2")
filtF1 <- tempfile(fileext=".fastq.gz")
filtR1 <- tempfile(fileext=".fastq.gz")

path <- "Sample_data/MiSeq_SOP"
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))

# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

## Inspect read qualitiy
```{r}
plotQualityProfile(fnFs[1:4])

plotQualityProfile(fnRs[1:4])
```
### Identify Primers

```{r primer-clean, echo=FALSE, cache=TRUE}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))

## Filter first 20 base pairs from forward and first 30 from reverse reads
filterAndTrim(fnFs, filtFs, fnRs, filtRs,
                     truncLen=c(30, 30),
              maxN = Inf, rm.phix=FALSE,
              compress=TRUE, multithread=TRUE)

#extract cut reads and align to view primers.
### Controls
fnFs_reads <- readFastq(filtFs)
fnFs_seq <- sread(fnFs_reads)

fnRs_reads <- readFastq(filtRs)
fnRs_seq <- sread(fnRs_reads)

```

#### Beginning of Forward Reads

The primer includes the first 16 bases. These were removed.

```{r forward primer plot, echo=FALSE, cache=TRUE,fig.height=2, fig.width=8}
#plot consensus
ggplot() +
  geom_logo( as.character(fnFs_seq), method = "probability" ) +
  theme_logo()

ggplot() +
  geom_logo( as.character(fnRs_seq), method = "probability" ) +
  theme_logo()
```


## Filter and Trim

The filterAndTrim(...) function filters the forward and reverse reads jointly, outputting only those pairs of reads that both pass the filter. In this function call we did four things: 
We removed the first trimLeft=10 nucleotides of each read.
We truncated the forward and reverse reads at truncLen=c(240, 200) nucleotides respectively. 
We filtered out all reads with more than maxN=0 ambiguous nucleotides. 
We filtered out all reads with more than two expected errors. The filtered output files were stored as gzipped fastq files (compress=TRUE).

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```
## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE)

errR <- learnErrors(filtRs, multithread=TRUE)

plotErrors(errF, nominalQ=TRUE)
```

## Dereplicate
```{r}
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names

errF <- learnErrors(derepFs, multithread=FALSE) # multithreading is available on many functions
errR <- learnErrors(derepRs, multithread=FALSE)
```

## Infer sample composition
```{r}
dadaFs <- dada(derepFs, err=errF, multithread=FALSE)

dadaRs <- dada(derepRs, err=errR, multithread=FALSE)

print(dadaFs)

dadaFs[[1]]
```

## Merge forward/reverse reads
```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```

## Create sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
table(nchar(getSequences(seqtab)))

```


## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)

sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through the pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))

# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

## Assign taxonomy

```{r assign-taxa, echo=FALSE, cache=TRUE}
taxa <- assignTaxonomy(seqtab.nochim, "Reference/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)

taxa <- addSpecies(taxa, "Reference/silva_species_assignment_v138.1.fa.gz")

```

```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

